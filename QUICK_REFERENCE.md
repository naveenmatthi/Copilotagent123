# Quick Reference - V1 to V2 Migration

## What Changed?

### ‚úÖ Azure Functions V2 Programming Model

**Before (V1):**
```python
def main(mytimer: func.TimerRequest) -> None:
    # function code
```

**After (V2):**
```python
app = func.FunctionApp()

@app.timer_trigger(schedule="0 */30 * * * *", arg_name="myTimer", 
                   run_on_startup=False, use_monitor=False)
def code42_sqs_to_loganalytics(myTimer: func.TimerRequest) -> None:
    # function code
```

### ‚ö° Timeout Prevention

**New Feature:**
```python
MAX_EXECUTION_TIME_SECONDS = 270  # 4.5 minutes

# Check before each message
elapsed_time = (datetime.now(timezone.utc) - start_time).total_seconds()
if elapsed_time > MAX_EXECUTION_TIME_SECONDS:
    logger.warning("Approaching timeout. Stopping processing.")
    break
```

### üöÄ Parallel S3 Processing

**Before:** Sequential (one file at a time)
```python
for record in records:
    process_s3_file(s3, record)  # Slow
```

**After:** Parallel (5 files at once)
```python
executor = ThreadPoolExecutor(max_workers=5)
futures = [executor.submit(process_s3_file, s3, record) for record in records]
for future in futures:
    result = future.result(timeout=60)
```

### üì§ Async Log Analytics Upload

**Before:** Synchronous with requests
```python
with requests.Session() as session:
    response = session.post(uri, data=body, headers=headers)
```

**After:** Asynchronous with aiohttp
```python
async with aiohttp.ClientSession() as session:
    async with session.post(uri, data=body, headers=headers) as response:
        # Faster, non-blocking
```

### üîÑ Improved Error Handling

**Before:** Retry entire message, delete on attempt
```python
for attempt in range(MAX_RETRIES):
    try:
        # process all records
        success = True
        break
    except Exception as e:
        logger.error(f"Attempt {attempt} failed")

if success:
    send_to_log_analytics(log_entries)
    sqs.delete_message(...)  # Delete even if send fails
```

**After:** Process individual files, delete only on success
```python
# Process files individually in parallel
for record in records:
    try:
        result = process_s3_file(s3, record)  # Isolated
        log_entries.extend(result)
    except Exception as e:
        logger.error(f"File failed: {e}")  # Continue to next

# Only delete if upload succeeds
if log_entries:
    success = send_to_log_analytics(log_entries)
    if success:
        sqs.delete_message(...)  # Safe deletion
```

## Key Configuration Changes

### Environment Variables (New/Changed)

```json
{
  "LOG_ANALYTICS_CHUNK_SIZE": "500",  // Configurable chunk size
  // All others remain the same
}
```

### host.json Updates

```json
{
  "functionTimeout": "00:05:00",  // Explicit timeout
  "retry": {                        // NEW: Retry policy
    "strategy": "fixedDelay",
    "maxRetryCount": 2,
    "delayInterval": "00:00:05"
  },
  "healthMonitor": {                // NEW: Health monitoring
    "enabled": true,
    "healthCheckInterval": "00:00:10"
  }
}
```

### requirements.txt

**Added:**
```
aiohttp          # Async HTTP client
azure-identity   # Managed Identity support
```

## Timer Schedule

**Changed:** Every 30 minutes (was unspecified in V1)
```python
schedule="0 */30 * * * *"  # Cron expression: minute, hour, day, month, weekday
```

**Other examples:**
- Every 15 min: `"0 */15 * * * *"`
- Every hour: `"0 0 * * * *"`
- Every 5 min: `"0 */5 * * * *"`

## Function Naming

**V1:** Generic `main`  
**V2:** Descriptive `code42_sqs_to_loganalytics`

## Deployment Command

**Same command, enhanced result:**
```powershell
func azure functionapp publish <function-app-name>
```

## Performance Improvements

| Aspect | V1 | V2 | Improvement |
|--------|----|----|-------------|
| S3 Processing | Sequential | Parallel (5x) | **5x faster** |
| Log Upload | Sync | Async | **2-3x faster** |
| Timeout Handling | None | Intelligent | **No data loss** |
| Error Recovery | Message-level | File-level | **Better resilience** |
| Message Deletion | On attempt | On success | **No duplicate work** |

## Estimated Time Savings

**Example workload:** 50 files, 1000 records each

| Metric | V1 | V2 |
|--------|----|----|
| S3 Download | 250s (5s √ó 50) | 50s (5s √ó 10 batches) |
| Processing | 100s | 100s |
| Upload | 150s | 60s (async) |
| **Total** | **~8 min** | **~3.5 min** |
| **Result** | ‚ùå Timeout | ‚úÖ Success |

## Migration Steps

1. **Backup V1 code** (keep for reference)
2. **Update function_app.py** with V2 code
3. **Update requirements.txt** with new dependencies
4. **Update host.json** with new settings
5. **Install dependencies**: `pip install -r requirements.txt`
6. **Test locally**: `func start`
7. **Deploy**: `func azure functionapp publish <name>`
8. **Monitor**: Check Application Insights

## Rollback Plan

If issues occur:

1. **Keep V1 code** in a separate branch/folder
2. **Monitor errors** in Application Insights
3. **Quick rollback**: Deploy V1 code
4. **Investigate**: Review logs and fix issues
5. **Redeploy V2**: After testing

## What Stays the Same?

- ‚úì AWS authentication (Managed Identity ‚Üí STS)
- ‚úì SQS polling logic
- ‚úì S3 file reading
- ‚úì Gzip decompression
- ‚úì JSON parsing
- ‚úì Log Analytics signature generation
- ‚úì Environment variables (except chunk size)
- ‚úì Core business logic

## Common Questions

**Q: Will V2 process more messages per run?**  
A: Yes, due to parallel processing and timeout prevention.

**Q: What if timeout still occurs?**  
A: Remaining messages stay in SQS for next run. Consider Premium plan or increase frequency.

**Q: Can I adjust parallel processing?**  
A: Yes, change `PARALLEL_S3_OPERATIONS = 5` to higher/lower value.

**Q: What about SQS visibility timeout?**  
A: Currently 360s (6 min). Increase if using Premium plan with longer timeout.

**Q: Will I lose data during migration?**  
A: No, messages remain in SQS until successfully processed.

## Monitoring V2

### Success Indicators
- ‚úÖ Execution time < 4 minutes
- ‚úÖ "Function execution completed" in logs
- ‚úÖ SQS messages deleted
- ‚úÖ Records in Log Analytics

### Warning Indicators  
- ‚ö†Ô∏è "Approaching timeout" in logs
- ‚ö†Ô∏è Execution time > 4.5 minutes
- ‚ö†Ô∏è SQS messages not deleted

### Error Indicators
- ‚ùå Function exceptions
- ‚ùå Failed Log Analytics uploads
- ‚ùå AWS authentication failures

## Support Resources

- **README.md** - Complete documentation
- **TIMEOUT_CONFIGURATION.md** - Detailed timeout strategies
- **TESTING_GUIDE.md** - Testing procedures
- **deploy.ps1** - Automated deployment script
